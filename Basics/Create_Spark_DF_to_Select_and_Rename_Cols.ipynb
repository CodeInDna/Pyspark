{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f21676",
   "metadata": {},
   "source": [
    "## Create spark dataframes to select and rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433cd84",
   "metadata": {},
   "source": [
    "#### Index\n",
    "\n",
    "[1. Create single column spark dataframe using list](#first) <br>\n",
    "[2. Create multi column spark dataframe using list](#second) <br>\n",
    "[3. Overview of Row](#third) <br>\n",
    "[4. Convert list of list into spark dataframe using Row](#fourth) <br>\n",
    "[5. Convert list of tuples into spark dataframe using Row](#fifth) <br>\n",
    "[6. Convert list of dicts into spark dataframe using Row](#sixth) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48deabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db79383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('CreateSparkDF') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a83adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"first_name\": \"Pheobe\",\n",
    "                \"last_name\": \"Buffay\",\n",
    "                \"phone_numbers\": Row(mobile= \"82349238942\", home= \"2348910249\", office= \"8273929\", shop=None),\n",
    "                \"courses\": [1, 3, 5, 7],\n",
    "                \"email\": \"pheobebuffay@abc.com\",\n",
    "                \"is_customer\": True,\n",
    "                \"amount_paid\": 1000.55,\n",
    "                \"customer_from\": datetime.date(2021, 1, 13),\n",
    "                \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"first_name\": \"Joey\",\n",
    "                \"last_name\": \"Tribbiani\",\n",
    "                \"phone_numbers\": Row(mobile= \"82349238942\", home= \"2348910249\", office= None, shop=None),\n",
    "                \"courses\": [2, 4, 5],\n",
    "                \"email\": \"joey@abc.com\",\n",
    "                \"is_customer\": True,\n",
    "                \"amount_paid\": 900.0,\n",
    "                \"customer_from\": datetime.date(2021, 2, 14),\n",
    "                \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "            },\n",
    "            {\n",
    "                \"id\": 3,\n",
    "                \"first_name\": \"Monica\",\n",
    "                \"last_name\": \"Geller\",\n",
    "                \"phone_numbers\": Row(mobile= None, home= None, office= None, shop=None),\n",
    "                \"courses\": [2],\n",
    "                \"email\": \"monica@abc.com\",\n",
    "                \"is_customer\": True,\n",
    "                \"amount_paid\": 1000.90,\n",
    "                \"customer_from\": datetime.date(2021, 2, 22),\n",
    "                \"last_updated_ts\": datetime.datetime(2021, 2, 28, 7, 33, 0)\n",
    "            },\n",
    "            {\n",
    "                \"id\": 4,\n",
    "                \"first_name\": \"Ross\",\n",
    "                \"last_name\": \"Geller\",\n",
    "                \"phone_numbers\": Row(mobile= \"82349238942\", home= None, office= None, shop=None),\n",
    "                \"courses\": [],\n",
    "                \"email\": \"ross@abc.com\",\n",
    "                \"is_customer\": True,\n",
    "                \"amount_paid\": 1200.55,\n",
    "                \"customer_from\": datetime.date(2021, 1, 19),\n",
    "                \"last_updated_ts\": datetime.datetime(2021, 2, 18, 1, 10, 0)\n",
    "            },\n",
    "            {\n",
    "                \"id\": 5,\n",
    "                \"first_name\": \"Rachel\",\n",
    "                \"last_name\": \"Green\",\n",
    "                \"phone_numbers\": Row(mobile= \"82349238942\", home= \"2348910249\", office= \"8273929\", shop= \"5343434654\"),\n",
    "                \"courses\": [3],\n",
    "                \"email\": \"rachel@abc.com\",\n",
    "                \"is_customer\": True,\n",
    "                \"amount_paid\": None,\n",
    "                \"customer_from\": datetime.date(2021, 2, 24),\n",
    "                \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "            },\n",
    "            {\n",
    "                \"id\": 6,\n",
    "                \"first_name\": \"Chandler\",\n",
    "                \"last_name\": \"Bing\",\n",
    "                \"phone_numbers\": Row(mobile= \"8273929\", home= None, office= None, shop=None),\n",
    "                \"courses\": [2, 4],\n",
    "                \"email\": \"bing@abc.com\",\n",
    "                \"is_customer\": True,\n",
    "                \"amount_paid\": 1000.80,\n",
    "                \"customer_from\": datetime.date(2021, 2, 22),\n",
    "                \"last_updated_ts\": datetime.datetime(2021, 2, 25, 7, 33, 0)\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52e4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b19352",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.createDataFrame(pd.DataFrame(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d41d142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|last_name|       phone_numbers|     courses|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Pheobe|   Buffay|[82349238942, 234...|[1, 3, 5, 7]|pheobebuffay@abc.com|       true|    1000.55|   2021-01-13|2021-02-10 01:15:00|\n",
      "|  2|      Joey|Tribbiani|[82349238942, 234...|   [2, 4, 5]|        joey@abc.com|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Monica|   Geller|               [,,,]|         [2]|      monica@abc.com|       true|     1000.9|   2021-02-22|2021-02-28 07:33:00|\n",
      "|  4|      Ross|   Geller|    [82349238942,,,]|          []|        ross@abc.com|       true|    1200.55|   2021-01-19|2021-02-18 01:10:00|\n",
      "|  5|    Rachel|    Green|[82349238942, 234...|         [3]|      rachel@abc.com|       true|        NaN|   2021-02-24|2021-02-18 03:33:00|\n",
      "|  6|  Chandler|     Bing|        [8273929,,,]|      [2, 4]|        bing@abc.com|       true|     1000.8|   2021-02-22|2021-02-25 07:33:00|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69818ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- phone_numbers: struct (nullable = true)\n",
      " |    |-- mobile: string (nullable = true)\n",
      " |    |-- home: string (nullable = true)\n",
      " |    |-- office: string (nullable = true)\n",
      " |    |-- shop: string (nullable = true)\n",
      " |-- courses: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- is_customer: boolean (nullable = true)\n",
      " |-- amount_paid: double (nullable = true)\n",
      " |-- customer_from: date (nullable = true)\n",
      " |-- last_updated_ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405e6ed",
   "metadata": {},
   "source": [
    "#### Overview of Narrow and Wide Transformations\n",
    "\n",
    "* Here are the functions related to narrow transformations. Narrow transformations doesn't result in shuffliing. These are also known as row level transformations.\n",
    "    * df.select\n",
    "    * df.filter\n",
    "    * df.withColumn\n",
    "    * df.withColumnRenamed\n",
    "    * df.drop\n",
    "* Here are the functions related to wide tranformations.\n",
    "    * df.distinct\n",
    "    * df.union or any set operation\n",
    "    * df.join or any join operation\n",
    "    * df.groupBy\n",
    "    * df.sort or df.orderBy\n",
    "* Any function that result in shuffling is wide transformation. For all the wide transformation, we have to deal with group of records based on a key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a239a9d",
   "metadata": {},
   "source": [
    "### df.select\n",
    "\n",
    "* `select()` function is used to select single, multiple, column by index, all columns from the list and the nested columns from a DataFrame.\n",
    "* PySpark `select()` is a transformation function hence it returns a new DataFrame with the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "553f927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method select in module pyspark.sql.dataframe:\n",
      "\n",
      "select(*cols) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Projects a set of expressions and returns a new :class:`DataFrame`.\n",
      "    \n",
      "    :param cols: list of column names (string) or expressions (:class:`Column`).\n",
      "        If one of the column names is '*', that column is expanded to include all columns\n",
      "        in the current :class:`DataFrame`.\n",
      "    \n",
      "    >>> df.select('*').collect()\n",
      "    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\n",
      "    >>> df.select('name', 'age').collect()\n",
      "    [Row(name='Alice', age=2), Row(name='Bob', age=5)]\n",
      "    >>> df.select(df.name, (df.age + 10).alias('age')).collect()\n",
      "    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(user_df.select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3cc03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|last_name|       phone_numbers|     courses|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Pheobe|   Buffay|[82349238942, 234...|[1, 3, 5, 7]|pheobebuffay@abc.com|       true|    1000.55|   2021-01-13|2021-02-10 01:15:00|\n",
      "|  2|      Joey|Tribbiani|[82349238942, 234...|   [2, 4, 5]|        joey@abc.com|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Monica|   Geller|               [,,,]|         [2]|      monica@abc.com|       true|     1000.9|   2021-02-22|2021-02-28 07:33:00|\n",
      "|  4|      Ross|   Geller|    [82349238942,,,]|          []|        ross@abc.com|       true|    1200.55|   2021-01-19|2021-02-18 01:10:00|\n",
      "|  5|    Rachel|    Green|[82349238942, 234...|         [3]|      rachel@abc.com|       true|        NaN|   2021-02-24|2021-02-18 03:33:00|\n",
      "|  6|  Chandler|     Bing|        [8273929,,,]|      [2, 4]|        bing@abc.com|       true|     1000.8|   2021-02-22|2021-02-25 07:33:00|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4e1daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select('id', 'first_name', 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "474c7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select(['id', 'first_name', 'last_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a9dd1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|last_name|       phone_numbers|     courses|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Pheobe|   Buffay|[82349238942, 234...|[1, 3, 5, 7]|pheobebuffay@abc.com|       true|    1000.55|   2021-01-13|2021-02-10 01:15:00|\n",
      "|  2|      Joey|Tribbiani|[82349238942, 234...|   [2, 4, 5]|        joey@abc.com|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Monica|   Geller|               [,,,]|         [2]|      monica@abc.com|       true|     1000.9|   2021-02-22|2021-02-28 07:33:00|\n",
      "|  4|      Ross|   Geller|    [82349238942,,,]|          []|        ross@abc.com|       true|    1200.55|   2021-01-19|2021-02-18 01:10:00|\n",
      "|  5|    Rachel|    Green|[82349238942, 234...|         [3]|      rachel@abc.com|       true|        NaN|   2021-02-24|2021-02-18 03:33:00|\n",
      "|  6|  Chandler|     Bing|        [8273929,,,]|      [2, 4]|        bing@abc.com|       true|     1000.8|   2021-02-22|2021-02-25 07:33:00|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining alias to the dataframe\n",
    "user_df.alias('u').select('u.*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba92cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select(col('id'), 'first_name', 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd2465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+---------------+\n",
      "| id|first_name|last_name|      full_name|\n",
      "+---+----------+---------+---------------+\n",
      "|  1|    Pheobe|   Buffay| Pheobe, Buffay|\n",
      "|  2|      Joey|Tribbiani|Joey, Tribbiani|\n",
      "|  3|    Monica|   Geller| Monica, Geller|\n",
      "|  4|      Ross|   Geller|   Ross, Geller|\n",
      "|  5|    Rachel|    Green|  Rachel, Green|\n",
      "|  6|  Chandler|     Bing| Chandler, Bing|\n",
      "+---+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select('id', 'first_name', 'last_name', concat('first_name', lit(', '), 'last_name').alias('full_name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a2bc89",
   "metadata": {},
   "source": [
    "### df.selectExpr \n",
    "\n",
    "* It performs same operations as `select()`.\n",
    "* `selectExpr()` is a way to integrate sql like syntax with dataframe API's to get the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ab5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method selectExpr in module pyspark.sql.dataframe:\n",
      "\n",
      "selectExpr(*expr) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Projects a set of SQL expressions and returns a new :class:`DataFrame`.\n",
      "    \n",
      "    This is a variant of :func:`select` that accepts SQL expressions.\n",
      "    \n",
      "    >>> df.selectExpr(\"age * 2\", \"abs(age)\").collect()\n",
      "    [Row((age * 2)=4, abs(age)=2), Row((age * 2)=10, abs(age)=5)]\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(user_df.selectExpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05715d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|last_name|       phone_numbers|     courses|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Pheobe|   Buffay|[82349238942, 234...|[1, 3, 5, 7]|pheobebuffay@abc.com|       true|    1000.55|   2021-01-13|2021-02-10 01:15:00|\n",
      "|  2|      Joey|Tribbiani|[82349238942, 234...|   [2, 4, 5]|        joey@abc.com|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Monica|   Geller|               [,,,]|         [2]|      monica@abc.com|       true|     1000.9|   2021-02-22|2021-02-28 07:33:00|\n",
      "|  4|      Ross|   Geller|    [82349238942,,,]|          []|        ross@abc.com|       true|    1200.55|   2021-01-19|2021-02-18 01:10:00|\n",
      "|  5|    Rachel|    Green|[82349238942, 234...|         [3]|      rachel@abc.com|       true|        NaN|   2021-02-24|2021-02-18 03:33:00|\n",
      "|  6|  Chandler|     Bing|        [8273929,,,]|      [2, 4]|        bing@abc.com|       true|     1000.8|   2021-02-22|2021-02-25 07:33:00|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.selectExpr('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bd1fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|last_name|       phone_numbers|     courses|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Pheobe|   Buffay|[82349238942, 234...|[1, 3, 5, 7]|pheobebuffay@abc.com|       true|    1000.55|   2021-01-13|2021-02-10 01:15:00|\n",
      "|  2|      Joey|Tribbiani|[82349238942, 234...|   [2, 4, 5]|        joey@abc.com|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Monica|   Geller|               [,,,]|         [2]|      monica@abc.com|       true|     1000.9|   2021-02-22|2021-02-28 07:33:00|\n",
      "|  4|      Ross|   Geller|    [82349238942,,,]|          []|        ross@abc.com|       true|    1200.55|   2021-01-19|2021-02-18 01:10:00|\n",
      "|  5|    Rachel|    Green|[82349238942, 234...|         [3]|      rachel@abc.com|       true|        NaN|   2021-02-24|2021-02-18 03:33:00|\n",
      "|  6|  Chandler|     Bing|        [8273929,,,]|      [2, 4]|        bing@abc.com|       true|     1000.8|   2021-02-22|2021-02-25 07:33:00|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.alias('u').selectExpr('u.*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6128fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.selectExpr('id', 'first_name', 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "270aa0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.selectExpr(['id', 'first_name', 'last_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7524d679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+---------------+\n",
      "| id|first_name|last_name|      full_name|\n",
      "+---+----------+---------+---------------+\n",
      "|  1|    Pheobe|   Buffay| Pheobe, Buffay|\n",
      "|  2|      Joey|Tribbiani|Joey, Tribbiani|\n",
      "|  3|    Monica|   Geller| Monica, Geller|\n",
      "|  4|      Ross|   Geller|   Ross, Geller|\n",
      "|  5|    Rachel|    Green|  Rachel, Green|\n",
      "|  6|  Chandler|     Bing| Chandler, Bing|\n",
      "+---+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sql like sytax to perform transformation\n",
    "user_df.selectExpr('id', 'first_name', 'last_name', \"concat(first_name, ', ', last_name) AS full_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51861479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to perform sql queries in spark\n",
    "\n",
    "# Convert dataframe into tempView\n",
    "user_df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "792a54a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+---------------+\n",
      "| id|first_name|last_name|      full_name|\n",
      "+---+----------+---------+---------------+\n",
      "|  1|    Pheobe|   Buffay| Pheobe, Buffay|\n",
      "|  2|      Joey|Tribbiani|Joey, Tribbiani|\n",
      "|  3|    Monica|   Geller| Monica, Geller|\n",
      "|  4|      Ross|   Geller|   Ross, Geller|\n",
      "|  5|    Rachel|    Green|  Rachel, Green|\n",
      "|  6|  Chandler|     Bing| Chandler, Bing|\n",
      "+---+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT id, first_name, last_name, concat(first_name, ', ', last_name) AS full_name FROM users\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4094b",
   "metadata": {},
   "source": [
    "### col()\n",
    "\n",
    "* Returns a Column based on the given column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cd8d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function col in module pyspark.sql.functions:\n",
      "\n",
      "col(col)\n",
      "    Returns a :class:`Column` based on the given column name.\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90913ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column<b'id'>, pyspark.sql.column.Column)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return column type object\n",
    "user_df['id'], type(user_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b4085b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column<b'id'>, pyspark.sql.column.Column)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col('id'), type(col('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a2d36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Multiple of 5|\n",
      "+-------------+\n",
      "|            5|\n",
      "|           10|\n",
      "|           15|\n",
      "|           20|\n",
      "|           25|\n",
      "|           30|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applied to whole column\n",
    "user_df.select((col('id') * 5).alias('Multiple of 5')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d15d8e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1588/22022411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'first_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'u' is not defined"
     ]
    }
   ],
   "source": [
    "# This does not work as there is no object by name u in this session(u is not in columnar format)\n",
    "user_df.alias('u').select(u['id'], col('first_name'), 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "161b9ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will work(here u is passed as a string)\n",
    "user_df.alias('u').select('u.id', col('first_name'), 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "754111b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Column is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1588/2653442577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'first_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mselectExpr\u001b[1;34m(self, *expr)\u001b[0m\n\u001b[0;32m   1433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1435\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1436\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m_jseq\u001b[1;34m(self, cols, converter)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_jseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;34m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_to_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_jmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m_to_seq\u001b[1;34m(sc, cols, converter)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0margs_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                         \u001b[0mtemp_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, object, gateway_client)\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mjava_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0margs_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                         \u001b[0mtemp_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, object, gateway_client)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mArrayList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJavaClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"java.util.ArrayList\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m             \u001b[0mjava_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Column is not iterable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;31m# string methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Column is not iterable"
     ]
    }
   ],
   "source": [
    "# This won't work as selectExpr only take column names or SQL style expression on column names\n",
    "user_df.selectExpr(col('id'), 'first_name', 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc18b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Runs effortlessly\n",
    "user_df.selectExpr('id', 'first_name', 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0b6edb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------------------+\n",
      "| id|first_name|last_name|concat(first_name,  , last_name)|\n",
      "+---+----------+---------+--------------------------------+\n",
      "|  1|    Pheobe|   Buffay|                   Pheobe Buffay|\n",
      "|  2|      Joey|Tribbiani|                  Joey Tribbiani|\n",
      "|  3|    Monica|   Geller|                   Monica Geller|\n",
      "|  4|      Ross|   Geller|                     Ross Geller|\n",
      "|  5|    Rachel|    Green|                    Rachel Green|\n",
      "|  6|  Chandler|     Bing|                   Chandler Bing|\n",
      "+---+----------+---------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.alias('u').selectExpr(\"u.id\", 'first_name', 'last_name', \"concat(u.first_name, ' ', u.last_name)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4362dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c6f08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------+\n",
      "| id|first_name|last_name|     full_name|\n",
      "+---+----------+---------+--------------+\n",
      "|  1|    Pheobe|   Buffay| Pheobe Buffay|\n",
      "|  2|      Joey|Tribbiani|Joey Tribbiani|\n",
      "|  3|    Monica|   Geller| Monica Geller|\n",
      "|  4|      Ross|   Geller|   Ross Geller|\n",
      "|  5|    Rachel|    Green|  Rachel Green|\n",
      "|  6|  Chandler|     Bing| Chandler Bing|\n",
      "+---+----------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT id, first_name, last_name,\n",
    "    concat(u.first_name, ' ', u.last_name) AS full_name\n",
    "    FROM users AS u\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddacafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| id|first_name|last_name|\n",
      "+---+----------+---------+\n",
      "|  1|    Pheobe|   Buffay|\n",
      "|  2|      Joey|Tribbiani|\n",
      "|  3|    Monica|   Geller|\n",
      "|  4|      Ross|   Geller|\n",
      "|  5|    Rachel|    Green|\n",
      "|  6|  Chandler|     Bing|\n",
      "+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['id', 'first_name', 'last_name']\n",
    "user_df.select(*cols).show()  # select() accepts string, list of string or variable elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f885ce",
   "metadata": {},
   "source": [
    "There are quite a few functions available on top of column type\n",
    "* `cast` (can be used on all important dataframe functions such as **select**, **filter**, **groupBy**, **orderBy** etc)\n",
    "* `asc`, `desc` (typically used as part of **sort** or **orderBy**)\n",
    "* `contains` (typically used as part of **filter** or **where**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0674879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- phone_numbers: struct (nullable = true)\n",
      " |    |-- mobile: string (nullable = true)\n",
      " |    |-- home: string (nullable = true)\n",
      " |    |-- office: string (nullable = true)\n",
      " |    |-- shop: string (nullable = true)\n",
      " |-- courses: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- is_customer: boolean (nullable = true)\n",
      " |-- amount_paid: double (nullable = true)\n",
      " |-- customer_from: date (nullable = true)\n",
      " |-- last_updated_ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e56fdb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|customer_from|\n",
      "+---+-------------+\n",
      "|  1|     20210113|\n",
      "|  2|     20210214|\n",
      "|  3|     20210222|\n",
      "|  4|     20210119|\n",
      "|  5|     20210224|\n",
      "|  6|     20210222|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select(\n",
    "    col('id'),\n",
    "    date_format('customer_from', 'yyyyMMdd').alias('customer_from')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8153456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- customer_from: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: customer_from converted to string type\n",
    "user_df.select(\n",
    "    col('id'),\n",
    "    date_format('customer_from', 'yyyyMMdd').alias('customer_from')\n",
    ").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a06e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- customer_from: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: cast customer_from to integer type\n",
    "user_df.select(\n",
    "    col('id'),\n",
    "    date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')\n",
    ").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdefb36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|customer_from|\n",
      "+---+-------------+\n",
      "|  1|     20210113|\n",
      "|  2|     20210214|\n",
      "|  3|     20210222|\n",
      "|  4|     20210119|\n",
      "|  5|     20210224|\n",
      "|  6|     20210222|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "cols = [col('id'), date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')]\n",
    "user_df.select(*cols).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14ddd6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'), ('customer_from', 'int')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.select(*cols).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047617ff",
   "metadata": {},
   "source": [
    "### concat()\n",
    "\n",
    "* Function to concat strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5764623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pyspark.sql.functions:\n",
      "\n",
      "concat(*cols)\n",
      "    Concatenates multiple input columns together into a single column.\n",
      "    The function works with strings, binary and compatible array columns.\n",
      "    \n",
      "    >>> df = spark.createDataFrame([('abcd','123')], ['s', 'd'])\n",
      "    >>> df.select(concat(df.s, df.d).alias('s')).collect()\n",
      "    [Row(s='abcd123')]\n",
      "    \n",
      "    >>> df = spark.createDataFrame([([1, 2], [3, 4], [5]), ([1, 2], None, [3])], ['a', 'b', 'c'])\n",
      "    >>> df.select(concat(df.a, df.b, df.c).alias(\"arr\")).collect()\n",
      "    [Row(arr=[1, 2, 3, 4, 5]), Row(arr=None)]\n",
      "    \n",
      "    .. versionadded:: 1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e2cf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = concat(col('first_name'), lit(', '), col('last_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9beca5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name_alias = full_name.alias('full_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "258d0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|      full_name|\n",
      "+---+---------------+\n",
      "|  1| Pheobe, Buffay|\n",
      "|  2|Joey, Tribbiani|\n",
      "|  3| Monica, Geller|\n",
      "|  4|   Ross, Geller|\n",
      "|  5|  Rachel, Green|\n",
      "|  6| Chandler, Bing|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select('id', full_name_alias).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a3754",
   "metadata": {},
   "source": [
    "### lit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "517d2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function lit in module pyspark.sql.functions:\n",
      "\n",
      "lit(col)\n",
      "    Creates a :class:`Column` of literal value.\n",
      "    \n",
      "    >>> df.select(lit(5).alias('height')).withColumn('spark_user', lit(True)).take(1)\n",
      "    [Row(height=5, spark_user=True)]\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80fda40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8659547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| id|amount_paid|\n",
      "+---+-----------+\n",
      "|  1|    1025.55|\n",
      "|  2|      925.0|\n",
      "|  3|     1025.9|\n",
      "|  4|    1225.55|\n",
      "|  5|        NaN|\n",
      "|  6|     1025.8|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT id, amount_paid + 25 AS amount_paid\n",
    "        FROM users\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61c92e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| id|amount_paid|\n",
      "+---+-----------+\n",
      "|  1|    1025.55|\n",
      "|  2|      925.0|\n",
      "|  3|     1025.9|\n",
      "|  4|    1225.55|\n",
      "|  5|        NaN|\n",
      "|  6|     1025.8|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.selectExpr('id', \"(amount_paid + 25) AS amount_paid\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d53ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|(amount_paid + 25)|\n",
      "+---+------------------+\n",
      "|  1|           1025.55|\n",
      "|  2|             925.0|\n",
      "|  3|            1025.9|\n",
      "|  4|           1225.55|\n",
      "|  5|               NaN|\n",
      "|  6|            1025.8|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will fail\n",
    "user_df.select(\"id\", col(\"amount_paid\") + 25).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "737f77f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|(25 + amount_paid)|\n",
      "+---+------------------+\n",
      "|  1|              null|\n",
      "|  2|              null|\n",
      "|  3|              null|\n",
      "|  4|              null|\n",
      "|  5|              null|\n",
      "|  6|              null|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will not work as we are adding string type to column type object\n",
    "user_df.select(\"id\", \"amount_paid\" + lit(25)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b19ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|(amount_paid + 25)|\n",
      "+---+------------------+\n",
      "|  1|           1025.55|\n",
      "|  2|             925.0|\n",
      "|  3|            1025.9|\n",
      "|  4|           1225.55|\n",
      "|  5|               NaN|\n",
      "|  6|            1025.8|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best option is to make sure both of them are column type object to perform addition\n",
    "user_df.select(\"id\", col(\"amount_paid\") + lit(25)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab83b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'25'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f589b",
   "metadata": {},
   "source": [
    "### Rename spark columns or expressions\n",
    "\n",
    "There are multiple wasy to rename spark dataframe columns or expressions.\n",
    "\n",
    "* Using `alias` as a part of `select`\n",
    "* Using `witColumn` on top of dataframe\n",
    "* Using `withColumnRenamed` on top of dataframe\n",
    "* Typically `withColumn` is used to perform row level transformations and then to provide a name to the result. If we provide the same name as existing column, then the column will be replaced with new one.\n",
    "* If we want to just rename the column then it is better to use `withColumnRenamed`\n",
    "* If we want to apply any transformations, we need to either use `select` or `withColumn`\n",
    "* We can rename bunch of columns or change the order of the columns using `toDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6011ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+---------------+\n",
      "| id|first_name|last_name|      full_name|\n",
      "+---+----------+---------+---------------+\n",
      "|  1|    Pheobe|   Buffay| Pheobe, Buffay|\n",
      "|  2|      Joey|Tribbiani|Joey, Tribbiani|\n",
      "|  3|    Monica|   Geller| Monica, Geller|\n",
      "|  4|      Ross|   Geller|   Ross, Geller|\n",
      "|  5|    Rachel|    Green|  Rachel, Green|\n",
      "|  6|  Chandler|     Bing| Chandler, Bing|\n",
      "+---+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using select and alias to create new column\n",
    "user_df.select('id', 'first_name', 'last_name',\n",
    "              concat('first_name', lit(', '), 'last_name').alias('full_name')\n",
    "              ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a4ec5",
   "metadata": {},
   "source": [
    "* Add another column by name `course_count` where it contains number of courses the user is enrolled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a6312da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+---------------+\n",
      "| id|first_name|last_name|      full_name|\n",
      "+---+----------+---------+---------------+\n",
      "|  1|    Pheobe|   Buffay| Pheobe, Buffay|\n",
      "|  2|      Joey|Tribbiani|Joey, Tribbiani|\n",
      "|  3|    Monica|   Geller| Monica, Geller|\n",
      "|  4|      Ross|   Geller|   Ross, Geller|\n",
      "|  5|    Rachel|    Green|  Rachel, Green|\n",
      "|  6|  Chandler|     Bing| Chandler, Bing|\n",
      "+---+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using withColumn\n",
    "user_df.select('id', 'first_name', 'last_name'). \\\n",
    "              withColumn('full_name', concat('first_name', lit(', '), 'last_name')\n",
    "              ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "33162f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------+\n",
      "| id|     first_name|last_name|\n",
      "+---+---------------+---------+\n",
      "|  1| Pheobe, Buffay|   Buffay|\n",
      "|  2|Joey, Tribbiani|Tribbiani|\n",
      "|  3| Monica, Geller|   Geller|\n",
      "|  4|   Ross, Geller|   Geller|\n",
      "|  5|  Rachel, Green|    Green|\n",
      "|  6| Chandler, Bing|     Bing|\n",
      "+---+---------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using withColumn with same name, replace the old data (❌ misleading)\n",
    "user_df.select('id', 'first_name', 'last_name'). \\\n",
    "              withColumn('first_name', concat('first_name', lit(', '), 'last_name')\n",
    "              ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e721b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|last_name|       phone_numbers|     courses|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Pheobe|   Buffay|[82349238942, 234...|[1, 3, 5, 7]|pheobebuffay@abc.com|       true|    1000.55|   2021-01-13|2021-02-10 01:15:00|\n",
      "|  2|      Joey|Tribbiani|[82349238942, 234...|   [2, 4, 5]|        joey@abc.com|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Monica|   Geller|               [,,,]|         [2]|      monica@abc.com|       true|     1000.9|   2021-02-22|2021-02-28 07:33:00|\n",
      "|  4|      Ross|   Geller|    [82349238942,,,]|          []|        ross@abc.com|       true|    1200.55|   2021-01-19|2021-02-18 01:10:00|\n",
      "|  5|    Rachel|    Green|[82349238942, 234...|         [3]|      rachel@abc.com|       true|        NaN|   2021-02-24|2021-02-18 03:33:00|\n",
      "|  6|  Chandler|     Bing|        [8273929,,,]|      [2, 4]|        bing@abc.com|       true|     1000.8|   2021-02-22|2021-02-25 07:33:00|\n",
      "+---+----------+---------+--------------------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43f61b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+\n",
      "| id|     courses|course_count|\n",
      "+---+------------+------------+\n",
      "|  1|[1, 3, 5, 7]|           4|\n",
      "|  2|   [2, 4, 5]|           3|\n",
      "|  3|         [2]|           1|\n",
      "|  4|          []|           0|\n",
      "|  5|         [3]|           1|\n",
      "|  6|      [2, 4]|           2|\n",
      "+---+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using withColumn\n",
    "user_df.select('id', 'courses'). \\\n",
    "              withColumn('course_count', size('courses')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8004d",
   "metadata": {},
   "source": [
    "* Rename `id` to `user_id`\n",
    "* Rename `first_name` to `user_first_name`\n",
    "* Rename `last_name` to `user_last_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25a83a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method withColumnRenamed in module pyspark.sql.dataframe:\n",
      "\n",
      "withColumnRenamed(existing, new) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` by renaming an existing column.\n",
      "    This is a no-op if schema doesn't contain the given column name.\n",
      "    \n",
      "    :param existing: string, name of the existing column to rename.\n",
      "    :param new: string, new name of the column.\n",
      "    \n",
      "    >>> df.withColumnRenamed('age', 'age2').collect()\n",
      "    [Row(age2=2, name='Alice'), Row(age2=5, name='Bob')]\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(user_df.withColumnRenamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d119734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+\n",
      "|user_id|user_first_name|user_last_name|\n",
      "+-------+---------------+--------------+\n",
      "|      1|         Pheobe|        Buffay|\n",
      "|      2|           Joey|     Tribbiani|\n",
      "|      3|         Monica|        Geller|\n",
      "|      4|           Ross|        Geller|\n",
      "|      5|         Rachel|         Green|\n",
      "|      6|       Chandler|          Bing|\n",
      "+-------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select('id', 'first_name', 'last_name'). \\\n",
    "              withColumnRenamed('id', 'user_id'). \\\n",
    "              withColumnRenamed('first_name', 'user_first_name'). \\\n",
    "              withColumnRenamed('last_name', 'user_last_name').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
